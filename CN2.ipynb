{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "FVqJFbRoTorO",
        "outputId": "0cd0cbeb-94f2-4154-f00b-42de69acc1de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60ef61af-2a2e-42ea-bb25-5338a5fb2b25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60ef61af-2a2e-42ea-bb25-5338a5fb2b25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60ef61af-2a2e-42ea-bb25-5338a5fb2b25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60ef61af-2a2e-42ea-bb25-5338a5fb2b25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ef44e53-d921-4f47-a01b-2999dca91e75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ef44e53-d921-4f47-a01b-2999dca91e75')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ef44e53-d921-4f47-a01b-2999dca91e75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Sp6t7DT2hv",
        "outputId": "e0f0e5e5-3f67-4114-b39c-2dc3b9da0500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib seaborn pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F8U_YQLVFdY",
        "outputId": "e02cea9a-2125-43be-a090-3c76b35b8b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic statistics of the dataset\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04309CeTVK0k",
        "outputId": "7313134a-c8fd-4875-eced-19159bc6570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
            "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
            "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
            "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
            "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
            "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
            "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
            "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
            "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
            "\n",
            "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
            "count  768.000000                768.000000  768.000000  768.000000  \n",
            "mean    31.992578                  0.471876   33.240885    0.348958  \n",
            "std      7.884160                  0.331329   11.760232    0.476951  \n",
            "min      0.000000                  0.078000   21.000000    0.000000  \n",
            "25%     27.300000                  0.243750   24.000000    0.000000  \n",
            "50%     32.000000                  0.372500   29.000000    0.000000  \n",
            "75%     36.600000                  0.626250   41.000000    1.000000  \n",
            "max     67.100000                  2.420000   81.000000    1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "lrT8jrScW0uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset visualization"
      ],
      "metadata": {
        "id": "pHGoLDFlboJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot to visualize relationships between numerical features\n",
        "sns.pairplot(df, hue='Outcome', diag_kind='kde')\n",
        "plt.title(\"Pairplot of Numerical Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4fKxx0aNV40M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for numerical features grouped by Outcome\n",
        "numerical_features = df.columns[:-1]\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x='Outcome', y=feature, data=df)\n",
        "    plt.title(f\"Box Plot of {feature} by Outcome\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "m8SUdZB5WBK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Countplot to show the distribution of the Outcome variable\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Outcome', data=df)\n",
        "plt.title(\"Distribution of Outcome\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2JdtXDgoWEcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CN2 algorithm in diabetes dataset"
      ],
      "metadata": {
        "id": "DDcx3HISbxaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections as clc\n",
        "import csv\n",
        "import random\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MJZVY5GVcBrk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CN2algorithm():\n",
        "\n",
        "    def __init__(self, train_data_csv, test_data_csv):\n",
        "        \"\"\"\n",
        "        Constructor: loads the train and test datasets, sets the minimum accepted significance value,\n",
        "        and maximum star size which limits the number of complexes considered for specialization.\n",
        "        \"\"\"\n",
        "        self.train_set = train_data_csv\n",
        "        self.test_set = test_data_csv\n",
        "        self.min_significance = 0.5\n",
        "        self.max_star_size = 7\n",
        "        self.accuracy = 0.2\n",
        "\n",
        "    def fit_CN2(self):\n",
        "\n",
        "\n",
        "        selectors = self.find_attribute_pairs()\n",
        "        remaining_examples = self.train_set\n",
        "        rule_list = []\n",
        "        # loop until data is all covered.\n",
        "        while len(remaining_examples) >= 1:\n",
        "            print(\"left\", len(remaining_examples))\n",
        "            best_new_rule_significance = 1\n",
        "            rules_to_specialise = []\n",
        "            existing_results = pd.DataFrame()\n",
        "            # i=0\n",
        "            # search rule space until rule best_new_rule_significance = 1significance is lower than user set boundary(0.5 for testing)\n",
        "            while best_new_rule_significance > self.min_significance:\n",
        "                # print(i)\n",
        "                # i=i+1\n",
        "                # calls statement if its first iteration of loop\n",
        "                if len(rules_to_specialise) == 0:\n",
        "                    ordered_rule_results = self.apply_and_order_rules_by_score(selectors, remaining_examples)\n",
        "                    trimmed_rule_results = ordered_rule_results[0:self.max_star_size]\n",
        "                elif len(rules_to_specialise) != 0:\n",
        "                    specialised_rules = self.specialise_complex(rules_to_specialise, selectors)\n",
        "                    # import ipdb;ipdb.set_trace(context=8)\n",
        "                    ordered_rule_results = self.apply_and_order_rules_by_score(specialised_rules, remaining_examples)\n",
        "                    trimmed_rule_results = ordered_rule_results[0:self.max_star_size]\n",
        "                # append newly discovered rules to existing ones, order them and then take best X(3 for testing)\n",
        "                existing_results = existing_results.append(trimmed_rule_results)\n",
        "                existing_results = self.order_rules(existing_results).iloc[0:2]\n",
        "                # update 'rules to specialise' and significance value of best new rule\n",
        "                rules_to_specialise = trimmed_rule_results['rule']\n",
        "                best_new_rule_significance = trimmed_rule_results['significance'].values[0]\n",
        "            # ipdb.set_trace(context=8)\n",
        "\n",
        "            # import ipdb;ipdb.set_trace(context=8)\n",
        "            best_rule = (existing_results['rule'].iloc[0], existing_results['predict_class'].iloc[0],\n",
        "                         existing_results['num_insts_covered'].iloc[0])\n",
        "            best_rule_coverage_index, best_rule_coverage_df = self.complex_coverage(best_rule[0], remaining_examples)\n",
        "            rule_list.append(best_rule)\n",
        "            remaining_examples = remaining_examples.drop(best_rule_coverage_index)\n",
        "\n",
        "        return rule_list\n",
        "\n",
        "    def test_fitted_model(self, possible_values, rule_list, data_set='default'):\n",
        "        \"\"\"\n",
        "        Test rule list returned by fit_CN2 function on test data(or manually supplied data)\n",
        "        returns a dataframe that contains the rule, rule acc, num of examples covered.\n",
        "        Also return general accuracy as average of each rule accuracy\n",
        "        \"\"\"\n",
        "        if type(data_set) == str:\n",
        "            data_set = self.test_set\n",
        "\n",
        "        remaining_examples = data_set\n",
        "        list_of_row_dicts = []\n",
        "        all_correct=0\n",
        "        all=len(data_set)\n",
        "\n",
        "\n",
        "        all_in_data = 0\n",
        "        for rule in rule_list:\n",
        "            rule_coverage_indexes, rule_coverage_dataframe = self.complex_coverage(rule[0], remaining_examples)\n",
        "\n",
        "            if len(rule_coverage_dataframe) == 0:\n",
        "                row_dictionary = {'rule': rule, 'pred_class': 'zero coverage', 'rule_acc': 0,\n",
        "                                  'num_examples': 0, 'num_correct': 0,\n",
        "                                  'num_wrong': 0}\n",
        "                list_of_row_dicts.append(row_dictionary)\n",
        "            # otherwise generate statistics about rule then save and remove examples from the data and test next rule.\n",
        "            else:\n",
        "\n",
        "                class_of_covered_examples = rule_coverage_dataframe['Outcome']\n",
        "\n",
        "                class_counts = class_of_covered_examples.value_counts()\n",
        "                rule_accuracy = class_counts.values[0] / sum(class_counts)\n",
        "                num_correctly_classified_examples = class_counts.values[0]\n",
        "                all_correct=all_correct+num_correctly_classified_examples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                num_incorrectly_classified_examples = sum(class_counts.values) - num_correctly_classified_examples\n",
        "                # print(\"corr\", num_correctly_classified_examples)\n",
        "                # print(num_incorrectly_classified_examples)\n",
        "\n",
        "                row_dictionary = {'rule': rule, 'pred_class': rule[1], 'rule_acc': rule_accuracy,\n",
        "                                  'num_examples': len(rule_coverage_indexes),\n",
        "                                  'num_correct': num_correctly_classified_examples,\n",
        "                                  'num_wrong': num_incorrectly_classified_examples}\n",
        "                list_of_row_dicts.append(row_dictionary)\n",
        "                # print(remaining_examples.values[rule_coverage_indexes])\n",
        "\n",
        "                remaining_examples = remaining_examples.drop(rule_coverage_indexes)\n",
        "                data_after = self.count_class_in_dataset(remaining_examples, possible_values)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        results = pd.DataFrame(list_of_row_dicts)\n",
        "        if (len([r for r in results['rule_acc'] if r != 0])==0):\n",
        "            overall_accuracy=0\n",
        "        else:\n",
        "            overall_accuracy = sum(results['rule_acc']) / len([r for r in results['rule_acc'] if r != 0])\n",
        "        # print(\"all\", all)\n",
        "        # print(\"all_correct\", all_correct)\n",
        "        print(\"accuracy2\", all_correct*100/all)\n",
        "        overall_accuracy=all_correct*100/all\n",
        "        self.accuracy = overall_accuracy\n",
        "        print(overall_accuracy)\n",
        "\n",
        "        return results, overall_accuracy\n",
        "\n",
        "    def count_class_in_dataset(self, data_set, possible_values):\n",
        "        result = pd.DataFrame(0, index=[1], columns=possible_values)\n",
        "        for i in range(len(data_set)):\n",
        "\n",
        "            result[str(data_set.iloc[i,-1])]=result[str(data_set.iloc[i,-1])]+1\n",
        "\n",
        "        return result\n",
        "\n",
        "    def apply_and_order_rules_by_score(self, complexes, data_set='default'):\n",
        "        \"\"\"\n",
        "        A function which takes a list of complexes/rules and returns a pandas DataFrame\n",
        "        that contains the complex, the entropy, the significance, the number of selectors,\n",
        "        the number of examples covered, the length of the rule and the predicted class of the rule.\n",
        "        The input param complexes should be a list of lists of tuples.\n",
        "        \"\"\"\n",
        "        # import ipdb;ipdb.set_trace(context=8)\n",
        "\n",
        "        # build a dictionary for each rule with relevant stats\n",
        "        if type(data_set) == str:\n",
        "            data_set = self.train_set\n",
        "        list_of_row_dicts = []\n",
        "        for row in complexes:\n",
        "            rule_coverage = self.complex_coverage(row, data_set)[1]\n",
        "            rule_length = len(row)\n",
        "            # test if rule covers 0 examples\n",
        "            if len(rule_coverage) == 0:\n",
        "\n",
        "                row_dictionary = {'rule': row, 'predict_class': 'dud rule',\n",
        "                                  'entropy': 10, 'laplace_accuracy': 0,\n",
        "                                  'significance': 0, 'length': rule_length,\n",
        "                                  'num_insts_covered': 0, 'specificity': 0}\n",
        "                list_of_row_dicts.append(row_dictionary)\n",
        "            # calculate stats for non 0 coverage rules\n",
        "            else:\n",
        "\n",
        "                num_examples_covered = len(rule_coverage)\n",
        "                entropy_of_rule = self.rule_entropy(rule_coverage)\n",
        "                significance_of_rule = self.rule_significance(rule_coverage)\n",
        "                laplace_accuracy_of_rule = self.rule_laplace_accuracy(rule_coverage)\n",
        "                class_attrib = rule_coverage['Outcome']\n",
        "                # import ipdb;ipdb.set_trace(context=8)\n",
        "                class_counts = class_attrib.value_counts()\n",
        "                majority_class = class_counts.axes[0][0]\n",
        "                rule_specificity = class_counts.values[0] / sum(class_counts)\n",
        "                row_dictionary = {'rule': row, 'predict_class': majority_class,\n",
        "                                  'entropy': entropy_of_rule, 'laplace_accuracy': laplace_accuracy_of_rule,\n",
        "                                  'significance': significance_of_rule, 'length': rule_length,\n",
        "                                  'num_insts_covered': num_examples_covered, 'specificity': rule_specificity}\n",
        "                list_of_row_dicts.append(row_dictionary)\n",
        "        # put dictionaries into dataframe and order them according to laplace acc, length\n",
        "        rules_and_stats = pd.DataFrame(list_of_row_dicts)\n",
        "        ordered_rules_and_stats = self.order_rules(rules_and_stats)\n",
        "\n",
        "        return ordered_rules_and_stats\n",
        "\n",
        "    def order_rules(self, dataFrame_of_rules):\n",
        "        \"\"\"\n",
        "        Function to order a dataframe of rules and stats according to laplace acc and length then reindex\n",
        "        the ordered frame.\n",
        "        \"\"\"\n",
        "        ordered_rules_and_stats = dataFrame_of_rules.sort_values(['entropy', 'length',\n",
        "                                                                  'num_insts_covered'], ascending=[True, True, False])\n",
        "        ordered_rules_and_stats = ordered_rules_and_stats.reset_index(drop=True)\n",
        "\n",
        "        return ordered_rules_and_stats\n",
        "\n",
        "    def find_attribute_pairs(self):\n",
        "        \"\"\"function to return the first set\n",
        "           of complexes which are the\n",
        "           1 attribute selectors\n",
        "        \"\"\"\n",
        "\n",
        "        # get attribute names\n",
        "        attributes = self.train_set.columns.values.tolist()\n",
        "\n",
        "        # remove class from list of attributes\n",
        "        del attributes[-1]\n",
        "\n",
        "        # get possible values for attributes\n",
        "        possAttribVals = {}\n",
        "        for att in attributes:\n",
        "            possAttribVals[att] = set(self.train_set[att])\n",
        "\n",
        "        # get list of attribute,value pairs\n",
        "        # from possAttribVals dictionary\n",
        "        attrib_value_pairs = []\n",
        "        for key in possAttribVals.keys():\n",
        "            for possVal in possAttribVals[key]:\n",
        "                attrib_value_pairs.append([(key, possVal)])\n",
        "\n",
        "        return attrib_value_pairs\n",
        "\n",
        "    def specialise_complex(self, target_complexes, selectors):\n",
        "        \"\"\"\n",
        "        Function to specialise the complexes in the \"star\", the current set of\n",
        "        complexes in consideration. Exepects to receive a complex (a list of tuples)\n",
        "        to which it adds addtional conjunctions using all the possible selectors. Returns\n",
        "        a list of new, specialised complexes.\n",
        "        \"\"\"\n",
        "        # import ipdb;ipdb.set_trace(context=8)\n",
        "\n",
        "        provisional_specialisations = []\n",
        "        for targ_complex in target_complexes:\n",
        "            for selector in selectors:\n",
        "                # check to see if target complex is a single tuple otherwise assume list of tuples\n",
        "                if type(targ_complex) == tuple:\n",
        "                    comp_to_specialise = [copy.copy(targ_complex)]\n",
        "                else:\n",
        "                    comp_to_specialise = copy.copy(targ_complex)\n",
        "\n",
        "                comp_to_specialise.append(selector[0])\n",
        "\n",
        "                # count if any slector is duplicated and append rule if not\n",
        "                count_of_selectors_in_complex = clc.Counter(comp_to_specialise)\n",
        "                flag = True\n",
        "                for count in count_of_selectors_in_complex.values():\n",
        "                    if count > 1:\n",
        "                        flag = False\n",
        "\n",
        "                if flag == True:\n",
        "                    provisional_specialisations.append(comp_to_specialise)\n",
        "\n",
        "        # remove complexes that have been specialised with same selector eg [(A=1),(A=1)]\n",
        "        # trimmed_specialisations = [rule for rule in provisional_specialisations if rule[0] != rule[1]]\n",
        "\n",
        "        return provisional_specialisations\n",
        "\n",
        "    def build_rule(self, passed_complex):\n",
        "        \"\"\"\n",
        "        build a rule in dict format where target attributes have a single value and non-target attributes\n",
        "        have a list of all possible values. Checks if there are repetitions in the attributes used, if so\n",
        "        it returns False\n",
        "        \"\"\"\n",
        "        atts_used_in_rule = []\n",
        "        for selector in passed_complex:\n",
        "            atts_used_in_rule.append(selector[0])\n",
        "        set_of_atts_used_in_rule = set(atts_used_in_rule)\n",
        "\n",
        "        if len(set_of_atts_used_in_rule) < len(atts_used_in_rule):\n",
        "            return False\n",
        "\n",
        "        rule = {}\n",
        "        attributes = self.train_set.columns.values.tolist()\n",
        "        for att in attributes:\n",
        "            rule[att] = list(set(self.train_set[att]))\n",
        "\n",
        "        for att_val_pair in passed_complex:\n",
        "            att = att_val_pair[0]\n",
        "            val = att_val_pair[1]\n",
        "            rule[att] = [val]\n",
        "        return rule\n",
        "\n",
        "    def complex_coverage(self, passed_complex, data_set='default'):\n",
        "        \"\"\" Returns set of instances of the data\n",
        "            which complex(rule) covers as a dataframe.\n",
        "        \"\"\"\n",
        "        if type(data_set) == str:\n",
        "            data_set = self.train_set\n",
        "        coverage = []\n",
        "\n",
        "        rule = self.build_rule(passed_complex)\n",
        "        if rule == False:\n",
        "            return [], []\n",
        "\n",
        "        mask = data_set.isin(rule).all(axis=1)\n",
        "\n",
        "        rule_coverage_indexes = data_set[mask].index.values\n",
        "        rule_coverage_dataframe = data_set[mask]\n",
        "\n",
        "        return rule_coverage_indexes, rule_coverage_dataframe\n",
        "\n",
        "    def check_rule_datapoint(self, datapoint, complex):\n",
        "        \"\"\"\n",
        "        Function to check if a given data point satisfies\n",
        "        the conditions of a given complex. Data point\n",
        "        should be a pandas Series. Complex should be a\n",
        "        tuple or a list of tuples where each tuple is of\n",
        "        the form ('Attribute', 'Value').\n",
        "        \"\"\"\n",
        "        if type(complex) == tuple:\n",
        "            print(complex[1])\n",
        "            if datapoint[complex[0]] == complex[1]:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        # import ipdb;ipdb.set_trace(context=8)\n",
        "        if type(complex) == list:\n",
        "            result = True\n",
        "            for selector in complex:\n",
        "                if datapoint[selector[0]] != selector[1]:\n",
        "                    result = False\n",
        "\n",
        "            return result\n",
        "\n",
        "    def rule_entropy(self, covered_data):\n",
        "        \"\"\"\n",
        "        Function to check the Shannon entropy of a complex/rule\n",
        "        given the instances it covers. Pass the instances\n",
        "        covered by the rule as a dataframe where class cloumn is\n",
        "        named class.\n",
        "        \"\"\"\n",
        "        class_series = covered_data['Outcome']\n",
        "        num_instances = len(class_series)\n",
        "        class_counts = class_series.value_counts()\n",
        "        class_probabilities = class_counts.divide(num_instances)\n",
        "        log2_of_classprobs = np.log2(class_probabilities)\n",
        "        plog2p = class_probabilities.multiply(log2_of_classprobs)\n",
        "        entropy = plog2p.sum() * -1\n",
        "\n",
        "        return entropy\n",
        "\n",
        "    def rule_significance(self, covered_data):\n",
        "        \"\"\"\n",
        "        Fucntion to check the significance of a rule using the\n",
        "        likelihood ratio test where observed frequency of class\n",
        "        in the coverage of the rule is compared to the observed\n",
        "        frequencies of the classes in the training data.\n",
        "        \"\"\"\n",
        "        covered_classes = covered_data['Outcome']\n",
        "        covered_num_instances = len(covered_classes)\n",
        "        covered_counts = covered_classes.value_counts()\n",
        "        covered_probs = covered_counts.divide(covered_num_instances)\n",
        "\n",
        "        train_classes = self.train_set['Outcome']\n",
        "        train_num_instances = len(train_classes)\n",
        "        train_counts = train_classes.value_counts()\n",
        "        train_probs = train_counts.divide(train_num_instances)\n",
        "\n",
        "        significance = covered_probs.multiply(np.log(covered_probs.divide(train_probs))).sum() * 2\n",
        "\n",
        "        return significance\n",
        "\n",
        "    def rule_laplace_accuracy(self, covered_data):\n",
        "        \"\"\"\n",
        "        function to calculate laplace accuracy of a rule, taken from update to CN2\n",
        "        paper by author of original CN2.\n",
        "        \"\"\"\n",
        "        # import ipdb;ipdb.set_trace(context=8)\n",
        "\n",
        "        class_series = covered_data['Outcome']\n",
        "        class_counts = class_series.value_counts()\n",
        "        num_instances = len(class_series)\n",
        "        num_classes = len(class_counts)\n",
        "        num_pred_class = class_counts.iloc[0]\n",
        "        # laplace_accuracy = (num_pred_class+1)/(num_instances+num_classes)\n",
        "        laplace_accuracy_2 = (num_instances + num_classes - num_pred_class - 1) / (num_instances + num_classes)\n",
        "        return laplace_accuracy_2\n",
        "\n",
        "    def check_for_all(self, rules, possible_values):\n",
        "        df1 = pd.DataFrame(0, index=possible_values,\n",
        "                           columns=possible_values)\n",
        "        data=self.test_set.copy()\n",
        "        for i in range(len(data)):\n",
        "\n",
        "            row = data.loc[i, :]\n",
        "            str_actual=str(data.loc[i, 'Outcome'])\n",
        "            string_pred=self.check(row, rules)\n",
        "            if string_pred is None:\n",
        "                string_pred = possible_values[0]\n",
        "            df1.loc[string_pred, str_actual] = df1.loc[string_pred, str_actual] + 1\n",
        "        print(df1)\n",
        "\n",
        "\n",
        "    def check(self, row, rules):\n",
        "        for rule in rules:\n",
        "            result = self.check_rule_datapoint(row, rule[0])\n",
        "            if result == True:\n",
        "                return str(rule[1])\n",
        "\n",
        "    def fit_CN2(self, laplace_threshold=0.7):\n",
        "        \"\"\"\n",
        "        Function to fit the CN2 model and perform Laplace accuracy pruning.\n",
        "        \"\"\"\n",
        "        selectors = self.find_attribute_pairs()\n",
        "        remaining_examples = self.train_set\n",
        "        rule_list = []\n",
        "\n",
        "        while len(remaining_examples) >= 1:\n",
        "            best_new_rule_significance = 1\n",
        "            rules_to_specialise = []\n",
        "            existing_results = pd.DataFrame()\n",
        "\n",
        "            while best_new_rule_significance > self.min_significance:\n",
        "                if len(rules_to_specialise) == 0:\n",
        "                    ordered_rule_results = self.apply_and_order_rules_by_score(selectors, remaining_examples)\n",
        "                    trimmed_rule_results = ordered_rule_results[0:self.max_star_size]\n",
        "                else:\n",
        "                    specialized_rules = self.specialise_complex(rules_to_specialise, selectors)\n",
        "                    ordered_rule_results = self.apply_and_order_rules_by_score(specialized_rules, remaining_examples)\n",
        "                    trimmed_rule_results = ordered_rule_results[0:self.max_star_size]\n",
        "\n",
        "                existing_results = existing_results.append(trimmed_rule_results)\n",
        "                existing_results = self.order_rules(existing_results).iloc[0:2]\n",
        "                rules_to_specialise = trimmed_rule_results['rule']\n",
        "                best_new_rule_significance = trimmed_rule_results['significance'].values[0]\n",
        "\n",
        "            best_rule = (existing_results['rule'].iloc[0], existing_results['predict_class'].iloc[0],\n",
        "                         existing_results['num_insts_covered'].iloc[0])\n",
        "            best_rule_coverage_index, best_rule_coverage_df = self.complex_coverage(best_rule[0], remaining_examples)\n",
        "            rule_list.append(best_rule)\n",
        "            remaining_examples = remaining_examples.drop(best_rule_coverage_index)\n",
        "    def test_fitted_model(self, possible_values, rule_list, data_set='default'):\n",
        "        if type(data_set) == str:\n",
        "            data_set = self.test_set\n",
        "            remaining_examples = data_set\n",
        "        list_of_row_dicts = []\n",
        "        all_correct = 0\n",
        "        all = len(data_set)\n",
        "\n",
        "        all_in_data = 0\n",
        "        for rule in rule_list:\n",
        "          rule_coverage_indexes, rule_coverage_dataframe = self.complex_coverage(rule[0], remaining_examples)\n",
        "\n",
        "          if len(rule_coverage_dataframe) == 0:\n",
        "            row_dictionary = {'rule': rule, 'pred_class': 'zero coverage', 'rule_acc': 0,\n",
        "                              'num_examples': 0, 'num_correct': 0,\n",
        "                              'num_wrong': 0}\n",
        "            list_of_row_dicts.append(row_dictionary)\n",
        "        # otherwise generate statistics about rule then save and remove examples from the data and test next rule.\n",
        "          else:\n",
        "            class_of_covered_examples = rule_coverage_dataframe['Outcome']\n",
        "            class_counts = class_of_covered_examples.value_counts()\n",
        "            rule_accuracy = class_counts.values[0] / sum(class_counts)\n",
        "            num_correctly_classified_examples = class_counts.values[0]\n",
        "            all_correct = all_correct + num_correctly_classified_examples\n",
        "\n",
        "            num_incorrectly_classified_examples = sum(class_counts.values) - num_correctly_classified_examples\n",
        "\n",
        "            row_dictionary = {'rule': rule, 'pred_class': rule[1], 'rule_acc': rule_accuracy,\n",
        "                              'num_examples': len(rule_coverage_indexes),\n",
        "                              'num_correct': num_correctly_classified_examples,\n",
        "                              'num_wrong': num_incorrectly_classified_examples}\n",
        "            list_of_row_dicts.append(row_dictionary)\n",
        "            remaining_examples = remaining_examples.drop(rule_coverage_indexes)\n",
        "\n",
        "        results = pd.DataFrame(list_of_row_dicts)\n",
        "        if (len([r for r in results['rule_acc'] if r != 0]) == 0):\n",
        "          overall_accuracy = 0\n",
        "        else:\n",
        "          overall_accuracy = sum(results['rule_acc']) / len([r for r in results['rule_acc'] if r != 0])\n",
        "        overall_accuracy = all_correct * 100 / all\n",
        "        self.accuracy = overall_accuracy\n",
        "\n",
        "        return results, overall_accuracy\n",
        "\n",
        "\n",
        "    def plot_decision_tree(self, tree_rules):\n",
        "        # Create a DataFrame from the converted rules\n",
        "        tree_df = pd.DataFrame(tree_rules)\n",
        "\n",
        "        # Convert categorical columns to numerical for plotting\n",
        "        for column in tree_df.columns:\n",
        "            if tree_df[column].dtype == 'O':\n",
        "                tree_df[column] = tree_df[column].astype('category').cat.codes\n",
        "\n",
        "        # Extract features and target\n",
        "        X = tree_df.drop('class', axis=1)\n",
        "        y = tree_df['class']\n",
        "\n",
        "        # Train a DecisionTreeClassifier\n",
        "        dt_classifier = DecisionTreeClassifier()\n",
        "        dt_classifier.fit(X, y)\n",
        "\n",
        "        # Plot the decision tree\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plot_tree(dt_classifier, feature_names=X.columns, class_names=dt_classifier.classes_, filled=True, rounded=True)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "UIV7y2ScN551"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUgzr_g55szR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"diabetes.csv\")\n",
        "cn2_model = CN2algorithm(train_data_csv=data, test_data_csv=data)\n",
        "rule_list = cn2_model.fit_CN2()\n",
        "tree_rules = cn2_model.convert_rules_to_tree_format(rule_list)\n",
        "cn2_model.plot_decision_tree(tree_rules)\n",
        "\n",
        "# Rest of your code\n",
        "test_results, overall_accuracy = cn2_model.test_fitted_model(possible_values=['class1', 'class2'], rule_list=rule_list, data_set=data)\n",
        "print(\"Test Results:\\n\", test_results)\n",
        "print(\"Overall Accuracy:\", overall_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inyQHcWZ5ZH5",
        "outputId": "73cf637d-105f-4974-e802-34d19029518d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n",
            "<ipython-input-18-9743261868e0>:416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  existing_results = existing_results.append(trimmed_rule_results)\n"
          ]
        }
      ]
    }
  ]
}